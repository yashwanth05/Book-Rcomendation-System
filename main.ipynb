{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "q0GwT1CIOnjX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "books = csv.reader(\"books.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "malpgPLwTVZi",
        "outputId": "d7d559fe-220b-4e2b-bbc4-2c09c6e7f82d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_csv.reader object at 0x00000191E8AAD900>\n"
          ]
        }
      ],
      "source": [
        "print(books)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "VnL4LAzOTWpm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxa7ee9-TZan",
        "outputId": "0d481e2c-b466-4b25-b6eb-ed873b99ec83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Yashwanth\\AppData\\Local\\Temp\\ipykernel_17456\\981790396.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('books.csv', error_bad_lines=False)\n",
            "Skipping line 3350: expected 12 fields, saw 13\n",
            "Skipping line 4704: expected 12 fields, saw 13\n",
            "Skipping line 5879: expected 12 fields, saw 13\n",
            "Skipping line 8981: expected 12 fields, saw 13\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('books.csv', error_bad_lines=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UYCxCZT2qn",
        "outputId": "c5648d91-d19b-4a8f-e2cc-058873b2ffdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   bookID                                              title  \\\n",
            "0       1  Harry Potter and the Half-Blood Prince (Harry ...   \n",
            "1       2  Harry Potter and the Order of the Phoenix (Har...   \n",
            "2       4  Harry Potter and the Chamber of Secrets (Harry...   \n",
            "3       5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
            "4       8  Harry Potter Boxed Set  Books 1-5 (Harry Potte...   \n",
            "\n",
            "                      authors  average_rating        isbn         isbn13  \\\n",
            "0  J.K. Rowling/Mary GrandPré            4.57  0439785960  9780439785969   \n",
            "1  J.K. Rowling/Mary GrandPré            4.49  0439358078  9780439358071   \n",
            "2                J.K. Rowling            4.42  0439554896  9780439554893   \n",
            "3  J.K. Rowling/Mary GrandPré            4.56  043965548X  9780439655484   \n",
            "4  J.K. Rowling/Mary GrandPré            4.78  0439682584  9780439682589   \n",
            "\n",
            "  language_code    num_pages  ratings_count  text_reviews_count  \\\n",
            "0           eng          652        2095690               27591   \n",
            "1           eng          870        2153167               29221   \n",
            "2           eng          352           6333                 244   \n",
            "3           eng          435        2339585               36325   \n",
            "4           eng         2690          41428                 164   \n",
            "\n",
            "  publication_date        publisher  \n",
            "0        9/16/2006  Scholastic Inc.  \n",
            "1         9/1/2004  Scholastic Inc.  \n",
            "2        11/1/2003       Scholastic  \n",
            "3         5/1/2004  Scholastic Inc.  \n",
            "4        9/13/2004       Scholastic  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "nvhRjYYYUd2H"
      },
      "outputs": [],
      "source": [
        "X = df[['title','authors','average_rating','ratings_count','text_reviews_count','publication_date','publisher']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "eDEAz_eNU0PX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "6a39_hiBIzgk"
      },
      "outputs": [],
      "source": [
        "#BELOW CODES TRY TO IMPLEMENT WORD2VEC IMPLEMENTATION TO CONVERT THE WORDS TO A NUMERIC FORMAT SO IT CAN BE PASSED INTO THE KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jobsbFfwjCBs",
        "outputId": "0fd8d965-9a42-4103-ffe2-ad4e7ad8a087"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Yashwanth\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Harry Potter', 'J.K. Rowling']\n"
          ]
        }
      ],
      "source": [
        "book_author = input(str(\"Enter the book name\"))\n",
        "b1 = book_author.split(\",\")\n",
        "\n",
        "print(b1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8RnrJQSMdAt",
        "outputId": "561a1fc1-07ce-4d49-8849-34523f7e88da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Yashwanth\\AppData\\Local\\Temp\\ipykernel_17456\\2015293995.py:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('books.csv', error_bad_lines=False)\n",
            "Skipping line 3350: expected 12 fields, saw 13\n",
            "Skipping line 4704: expected 12 fields, saw 13\n",
            "Skipping line 5879: expected 12 fields, saw 13\n",
            "Skipping line 8981: expected 12 fields, saw 13\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Books similar to 'Harry Potter':\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Step 1: Load the dataset from the CSV file\n",
        "df = pd.read_csv('books.csv', error_bad_lines=False)\n",
        "\n",
        "# Step 2: Preprocess and tokenize the book names\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "df['title_tokens'] = df['title'].apply(preprocess_text)\n",
        "\n",
        "# Step 3: Train Word2Vec model\n",
        "model = Word2Vec(sentences=df['title_tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Step 4 and 5: Function to find most similar book names\n",
        "def find_similar_books(input_title, model, df, top_n=100):\n",
        "    input_title_tokens = preprocess_text(input_title)\n",
        "    similar_books = []\n",
        "    for _, row in df.iterrows():\n",
        "        title_tokens = row['title_tokens']\n",
        "        similarity_score = model.wv.n_similarity(input_title_tokens, title_tokens)\n",
        "        similar_books.append((row['title'], similarity_score))\n",
        "\n",
        "    similar_books.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Filter out the input book and any duplicates from the recommendations\n",
        "    unique_similar_books = []\n",
        "    seen_titles = set()\n",
        "    for book, score in similar_books:\n",
        "        if book != input_title and book not in seen_titles:\n",
        "            unique_similar_books.append((book, score))\n",
        "            seen_titles.add(book)\n",
        "\n",
        "    return unique_similar_books[:top_n]\n",
        "\n",
        "# Example usage\n",
        "# input_book = \"Harry potter\"\n",
        "similar_books = find_similar_books(b1[0], model, df)\n",
        "\n",
        "books_ti = []\n",
        "print(f\"Books similar to '{b1[0]}':\")\n",
        "for book, score in similar_books:\n",
        "    books_ti.append(book)\n",
        "    # print(f\"- {book} (Similarity Score: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Yashwanth\\AppData\\Local\\Temp\\ipykernel_17456\\387860061.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('books.csv', error_bad_lines=False)\n",
            "Skipping line 3350: expected 12 fields, saw 13\n",
            "Skipping line 4704: expected 12 fields, saw 13\n",
            "Skipping line 5879: expected 12 fields, saw 13\n",
            "Skipping line 8981: expected 12 fields, saw 13\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Books similar to 'J.K. Rowling':\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from itertools import chain\n",
        "\n",
        "# Step 1: Load the dataset from the CSV file\n",
        "df = pd.read_csv('books.csv', error_bad_lines=False)\n",
        "\n",
        "# Step 2: Preprocess and tokenize the book names\n",
        "def preprocess_text(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "df['authors_tokens'] = df['authors'].apply(preprocess_text)\n",
        "\n",
        "# Step 3: Train Word2Vec model\n",
        "model = Word2Vec(sentences=df['authors_tokens'], vector_size=10, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Step 4 and 5: Function to find most similar book names\n",
        "def find_similar_books(input_title, model, df, top_n=100):\n",
        "    input_title_tokens = preprocess_text(input_title)\n",
        "    similar_books = []\n",
        "    for _, row in df.iterrows():\n",
        "        title_tokens = row['authors_tokens']\n",
        "        similarity_score = model.wv.n_similarity(input_title_tokens, title_tokens)\n",
        "        similar_books.append((row['authors'], similarity_score))\n",
        "\n",
        "    similar_books.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Filter out the input book and any duplicates from the recommendations\n",
        "    unique_similar_books = []\n",
        "    seen_titles = set()\n",
        "    for book, score in similar_books:\n",
        "        if book != input_title and book not in seen_titles:\n",
        "            unique_similar_books.append((book, score))\n",
        "            seen_titles.add(book)\n",
        "\n",
        "    return unique_similar_books[:top_n]\n",
        "\n",
        "# Example usage\n",
        "# input_book = \"J.K. Rowling\"\n",
        "similar_books = find_similar_books(b1[1], model, df)\n",
        "\n",
        "books_au = []\n",
        "print(f\"Books similar to '{b1[1]}':\")\n",
        "for book, score in similar_books:\n",
        "    # Use the loc function to filter rows based on the value in 'Name' and access the 'City' column\n",
        "    city_data = df.loc[df['authors'] == book, 'title']\n",
        "    boo = city_data .to_string(index=False)\n",
        "    books_au.append(boo)\n",
        "    # print(f\"- {city_data} {book} (Similarity Score: {score:.4f})\")\n",
        "# print((books_au))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "list1 = books_au\n",
        "list2 = books_ti\n",
        "main_books = []\n",
        "# Calculate similarity ratio for each pair of strings in the lists\n",
        "for str1 in list1:\n",
        "    for str2 in list2:\n",
        "        similarity_ratio = SequenceMatcher(None, str1, str2).ratio()\n",
        "        if similarity_ratio > 0.60:\n",
        "            # print(f\"Similarity between '{str1}' and '{str2}': {similarity_ratio}\")\n",
        "            main_books.append(str1)\n",
        "            main_books.append(str2)\n",
        "            modified_l1 = set(main_books)\n",
        "            modified_li = list(modified_l1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiSBUCDUhusR",
        "outputId": "502deb53-348c-46e6-d652-f490425cc722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Books similar to the input book:\n",
            "       bookID                                              title  \\\n",
            "0           1  Harry Potter and the Half-Blood Prince (Harry ...   \n",
            "2           4  Harry Potter and the Chamber of Secrets (Harry...   \n",
            "3           5  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
            "615      2005  Harry Potter and the Half-Blood Prince (Harry ...   \n",
            "1233     4256  Harry Potter and the Prisoner of Azkaban (Harr...   \n",
            "1916     6866            Fodor's Amsterdam (Fodor's Gold Guides)   \n",
            "4415    15881  Harry Potter and the Chamber of Secrets (Harry...   \n",
            "8873    34318  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
            "9303    36606  Oliver and Albert  Friends Forever (Easy-to-Re...   \n",
            "9805    39357         Bride & Groom (A Dog Lover's Mystery  #16)   \n",
            "9811    39365     Scratch the Surface (A Cat Lover's Mystery #1)   \n",
            "10345   41909    Harry Potter ve Sırlar Odası (Harry Potter  #2)   \n",
            "10674   43504  Harry Potter and the Philosopher's Stone (Harr...   \n",
            "10675   43509  Harry Potter and the Goblet of Fire (Harry Pot...   \n",
            "\n",
            "                                           authors  average_rating  \\\n",
            "0                       J.K. Rowling/Mary GrandPré            4.57   \n",
            "2                                     J.K. Rowling            4.42   \n",
            "3                       J.K. Rowling/Mary GrandPré            4.56   \n",
            "615                                   J.K. Rowling            4.57   \n",
            "1233                                  J.K. Rowling            4.56   \n",
            "1916   Fodor's Travel Publications Inc./Sarah Gold            3.43   \n",
            "4415                    J.K. Rowling/Mary GrandPré            4.42   \n",
            "8873                    J.K. Rowling/Mary GrandPré            4.47   \n",
            "9303              Jean Van Leeuwen/Ann Schweninger            3.61   \n",
            "9805                    Susan Conant/Maxwell Award            3.78   \n",
            "9811                                  Susan Conant            3.34   \n",
            "10345                     J.K. Rowling/Sevin Okyay            4.42   \n",
            "10674                                 J.K. Rowling            4.47   \n",
            "10675                                 J.K. Rowling            4.56   \n",
            "\n",
            "             isbn         isbn13 language_code    num_pages  ratings_count  \\\n",
            "0      0439785960  9780439785969           eng          652        2095690   \n",
            "2      0439554896  9780439554893           eng          352           6333   \n",
            "3      043965548X  9780439655484           eng          435        2339585   \n",
            "615    0747584664  9780747584667           eng          768           1213   \n",
            "1233   074757362X  9780747573623           eng          480           3141   \n",
            "1916   1400016088  9781400016082           eng          288              6   \n",
            "4415   0439064864  9780439064866           eng          341        2293963   \n",
            "8873   0786222727  9780786222728           eng          424            147   \n",
            "9303   0142300845  9780142300848           eng           48             23   \n",
            "9805   0425200744  9780425200742           eng          262            263   \n",
            "9811   0425206114  9780425206119           eng          288             23   \n",
            "10345  3570211029  9783570211021           tur          403           1000   \n",
            "10674  158234681X  9781582346816           gla          250             11   \n",
            "10675  074754624X  9780747546245           eng          636          18754   \n",
            "\n",
            "       text_reviews_count publication_date  \\\n",
            "0                   27591        9/16/2006   \n",
            "2                     244        11/1/2003   \n",
            "3                   36325         5/1/2004   \n",
            "615                    78        6/23/2006   \n",
            "1233                  140         7/1/2008   \n",
            "1916                    0         4/6/2004   \n",
            "4415                34692         6/2/1999   \n",
            "8873                   13       11/12/1999   \n",
            "9303                    2        3/18/2002   \n",
            "9805                   19         1/4/2005   \n",
            "9811                    2         7/5/2006   \n",
            "10345                  41        10/1/2001   \n",
            "10674                   0         7/1/2010   \n",
            "10675                 906         7/8/2000   \n",
            "\n",
            "                                      publisher  \\\n",
            "0                               Scholastic Inc.   \n",
            "2                                    Scholastic   \n",
            "3                               Scholastic Inc.   \n",
            "615                       Bloomsbury Publishing   \n",
            "1233                              Bloomsbury UK   \n",
            "1916                                    Fodor's   \n",
            "4415   Arthur A. Levine Books / Scholastic Inc.   \n",
            "8873                Thorndike Press Large Print   \n",
            "9303                                     Puffin   \n",
            "9805                                    Berkley   \n",
            "9811                                    Berkley   \n",
            "10345                      Yapı Kredi Yayınları   \n",
            "10674                  Bloomsbury USA Childrens   \n",
            "10675                                Bloomsbury   \n",
            "\n",
            "                                          authors_tokens  \n",
            "0                         [j.k., rowling/mary, grandpré]  \n",
            "2                                        [j.k., rowling]  \n",
            "3                         [j.k., rowling/mary, grandpré]  \n",
            "615                                      [j.k., rowling]  \n",
            "1233                                     [j.k., rowling]  \n",
            "1916   [fodor, 's, travel, publications, inc./sarah, ...  \n",
            "4415                      [j.k., rowling/mary, grandpré]  \n",
            "8873                      [j.k., rowling/mary, grandpré]  \n",
            "9303               [jean, van, leeuwen/ann, schweninger]  \n",
            "9805                      [susan, conant/maxwell, award]  \n",
            "9811                                     [susan, conant]  \n",
            "10345                       [j.k., rowling/sevin, okyay]  \n",
            "10674                                    [j.k., rowling]  \n",
            "10675                                    [j.k., rowling]  \n"
          ]
        }
      ],
      "source": [
        "# similar_books_titles = [book for book, _ in modified_li]\n",
        "similar_books_df = df[df['title'].isin(modified_li)].copy()\n",
        "\n",
        "# Print the similar books with all their columns\n",
        "print(\"Books similar to the input book:\")\n",
        "print(similar_books_df)\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "similar_books_df.to_csv('similar_books.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgYRxdp7fO3d"
      },
      "source": [
        "#DISPLAYING BOOK IMAGES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "x4wh4hTIgwC_",
        "outputId": "56c05ae0-449e-4ce8-8b63-e89d04d5762c"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "# from PIL import Image\n",
        "# from io import BytesIO\n",
        "\n",
        "# def get_book_image(title):\n",
        "#     \"\"\"Gets the image URL for a book title using the Google Books API.\"\"\"\n",
        "#     url = \"https://www.googleapis.com/books/v1/volumes?q=\" + title\n",
        "#     response = requests.get(url)\n",
        "#     data = response.json()\n",
        "\n",
        "#     if \"items\" in data and data[\"items\"]:\n",
        "#         book_info = data[\"items\"][0][\"volumeInfo\"]\n",
        "#         if \"imageLinks\" in book_info:\n",
        "#             image_url = book_info[\"imageLinks\"].get(\"thumbnail\", \"\")\n",
        "#             return image_url\n",
        "\n",
        "#     return \"\"\n",
        "\n",
        "# def plot_book_images(titles, image_urls):\n",
        "#     n_books = len(titles)\n",
        "#     n_cols = 2\n",
        "#     n_rows = (n_books + n_cols - 1) // n_cols  # Calculate the number of rows needed\n",
        "\n",
        "#     fig_width = 5 # Adjust the figure width\n",
        "#     fig_height = n_rows * 3  # Adjust the figure height based on the number of rows\n",
        "\n",
        "#     fig, ax = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height))\n",
        "\n",
        "#     for i, title in enumerate(titles):\n",
        "#         if image_urls[i]:\n",
        "#             response = requests.get(image_urls[i])\n",
        "#             image = Image.open(BytesIO(response.content))\n",
        "#             # Get the original aspect ratio of the image\n",
        "#             aspect_ratio = image.width / image.height\n",
        "#             # Calculate the new height to preserve aspect ratio and fit within 150px width\n",
        "#             new_height = int(100 / aspect_ratio)\n",
        "#             image = image.resize((100, new_height))  # Resize the image with correct aspect ratio\n",
        "#             imagebox = OffsetImage(image)\n",
        "#             x_pos = i % n_cols\n",
        "#             y_pos = i // n_cols\n",
        "#             ab = AnnotationBbox(imagebox, (x_pos, y_pos), frameon=False)\n",
        "#             ax[y_pos, x_pos].add_artist(ab)\n",
        "\n",
        "#         ax[y_pos, x_pos].set_title(title)\n",
        "#         ax[y_pos, x_pos].axis(\"off\")\n",
        "\n",
        "#     # Remove empty subplots if the number of books is not a multiple of 2\n",
        "#     if n_books % 2 != 0:\n",
        "#         ax[-1, -1].axis(\"off\")\n",
        "\n",
        "#     for i in range(n_rows):\n",
        "#         for j in range(n_cols):\n",
        "#             if i * n_cols + j >= n_books:  # Turn off unused subplots\n",
        "#                 ax[i, j].axis(\"off\")\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# def main():\n",
        "#     # Get the book titles from the user.\n",
        "#     # input_string = input(\"Enter four book titles separated by commas: \")\n",
        "#     # titles = [title.strip() for title in input_string.split(\",\")]\n",
        "\n",
        "\n",
        "#     # Get the image URLs for the books.\n",
        "#     image_urls = [get_book_image(title) for title in similar_books_titles]\n",
        "\n",
        "#     # Plot the images of the books.\n",
        "#     plot_book_images(similar_books_titles, image_urls)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sntMDHWhkmP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
